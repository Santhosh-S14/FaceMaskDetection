# -*- coding: utf-8 -*-
"""AI_Final_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nqCWmhq9aq5y9GM9C5oM9ct1slexSMSO

<h1>Project Assignment Part - I</h1>
<h5>COMP 6721 Applied Artificial Intelligence</h5>
<ul>
<li>40161500 - Parth Ashokkumar Parekh</li>
<li>40202625 - Santhosh Santhanam</li>
<li>40193868 - Elvin Rejimone</li>
</ul>
"""

# from google.colab import drive
# drive.mount('/content/drive')

# Import packages

import torch
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from sklearn.model_selection import train_test_split
from torch.utils.data import Subset
from collections import Counter
import matplotlib.pyplot as plt
import torch.nn as nn
from torch.utils.data import DataLoader
from PIL import Image
import torch.nn.functional as F
import torchvision
from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report, precision_recall_fscore_support
from torchvision import models
from torchsummary import summary

config = {
    'images_folder': 'E:\\Masters\\Concordia\\Winter 2022\\COMP 6721\\Project\\Dataset\\train',
    'train_batch_size': 64,
    'test_batch_size': 64,
    'valid_batch_size': 64,
    'num_epochs': 20,
    'input_size': 1024,
    'learning_rate': 0.001
}

savedModel = False
model_path = 'E:\\Masters\\Concordia\\Winter 2022\\COMP 6721\\Project\\Dataset'

def get_images(images_path, test_split=0.20):
    transform = transforms.Compose([transforms.ToTensor(), transforms.Resize([32, 32]),
                                    transforms.Normalize((6.4307e-02, -6.7064e-05, -2.5857e-03), (0.9544, 0.9539, 0.9665))])
    dataset = ImageFolder(images_path, transform=transform)

    classLabels = dataset.class_to_idx;
    classImages = dict(Counter(dataset.targets))

    # print(classImages)
    print("\n")

    # Plotting the bar graph of the data
    keys = ["cloth", "n95", "n95 with valve", "surgical", "without mask"]
    values = list(classImages.values())
    plt.bar(keys, values, color ='blue',width = 0.4)
    plt.xlabel("Type of classes")
    plt.ylabel("Number of images")
    plt.title("Number of images in each each mask type")
    plt.show()

    # Showing count of each image
    print("\n")
    for k in keys:
      print(k + ": " + str(classImages[classLabels[k]]))

    train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=test_split)
    train = Subset(dataset, train_idx)
    test = Subset(dataset, test_idx)

    return train, test

train_data, test_data = get_images(config['images_folder'])

# Getting train and test loader
train_dataloader = DataLoader(train_data, batch_size=config["train_batch_size"], shuffle=True,
                                  pin_memory=False)
test_dataloader = DataLoader(test_data, batch_size=config["test_batch_size"], shuffle=False,
                                 pin_memory=False)

# CNN model

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv_layer = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        self.fc_layer = nn.Sequential(
            nn.Dropout(p=0.1),
            nn.Linear(8 * 8 * 64, 1000),
            nn.ReLU(inplace=True),
            nn.Linear(1000, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.1),
            nn.Linear(512, 5)
        )

    def forward(self, x):
        # conv layers
        x = self.conv_layer(x)
        # flatten
        x = x.view(x.size(0), -1)
        # fc layer
        x = self.fc_layer(x)
        return x

# Print the device
device = 'cuda' if torch.cuda.is_available() else "cpu"
print(device)

if savedModel:
  model = Model()
  model.load_state_dict(torch.load(model_path, torch.device('cpu')))
  model.eval()
  model.to(device)
  summary(model, (3, 32, 32))
else:
  model = Model()
  model = model.to(device)
  summary(model, (3, 32, 32))
  optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])
  criterion = nn.CrossEntropyLoss()

# Model training class

class ModelTraining:

    def __init__(self, model, device, optimizer, criteria):
        self.model = model
        self.device = device
        self.optimizer = optimizer
        self.criteria = criteria

    def training(self, train_dataloader, epochs):
        total_no_of_steps = len(train_dataloader)
        accuracyList = []
        trainingLoss = []
        for epoch in range(epochs):
            self.model.train()
            train_total = 0
            train_correct = 0
            for i, (images, labels) in enumerate(train_dataloader):
                images = images.to(self.device)
                labels = labels.to(self.device)

                outputs = self.model(images)
                loss = self.criteria(outputs, labels)

                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

                _, predicted = torch.max(outputs.data, 1)
                train_total += labels.shape[0]
                train_correct += (predicted == labels).sum().item()
            print(
                f'Epoch {epoch + 1} / {epochs}, Training loss = {loss.item():.4f}, Training accuracy = {(train_correct / train_total) * 100}')
            accuracyList.append((train_correct / train_total) * 100)
            trainingLoss.append(loss.item())
        return accuracyList, trainingLoss
                # f', Validation loss = {validation_loss.item():.4f}, Validation accuracy = {(correct / total) * 100}')

# Training the model
if not savedModel:
  model_trainer = ModelTraining(model=model, device=device, optimizer=optimizer, criteria=criterion)
  accuracyList, trainingLossList = model_trainer.training(train_dataloader, epochs=config["num_epochs"])
  torch.save(model.state_dict(), "trainedModel2")

# Plot the graph of training accuracy vs the epoch
plt.plot(range(1, config['num_epochs']+1), accuracyList, 'r--')
plt.xlabel('Epoch')
plt.ylabel('Training accuracy')

# Plot the graph of training loss vs the epoch
plt.plot(range(1, config['num_epochs']+1), trainingLossList, 'b--')
plt.xlabel('Epoch')
plt.ylabel('Training Loss')

# Getting the accuracy of the model
def getModelAccuracy(model, test_dataloader, device):
    model.eval()
    total = 0
    correct = 0
    y_pred = []
    y_true = []
    precision = dict()
    recall = dict()
    avg = dict()
    with torch.no_grad():
        for images, labels in test_dataloader:
            images = images.to(device)
            labels = labels.to(device)
            model_pred_on_test = model(images)
            model_pred_on_test = torch.argmax(F.softmax(model_pred_on_test.data), 1)
            predicted = model_pred_on_test
            total += labels.shape[0]
            correct += (predicted == labels).sum().item()
            if y_pred == []:
              y_true = labels[:]
              y_pred = model_pred_on_test[:]
            else:
              y_true = torch.hstack([y_true, labels])
              y_pred = torch.hstack([y_pred, model_pred_on_test])
        print('Test Accuracy of the model on the test images: {} %'
              .format((correct / total) * 100))
        y_pred = y_pred.cpu().detach().numpy()
        y_true = y_true.cpu().detach().numpy()
        target_names = ['cm', 'n95', 'n95v', 'sm', 'no mask']
        labels_names = [0, 1, 2, 3, 4]
        print(classification_report(y_true, y_pred, labels=labels_names, target_names=target_names))
        cm = confusion_matrix(y_true, y_pred, labels=labels_names)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)
        disp = disp.plot(cmap=plt.cm.Blues, values_format='g')
        plt.show()

getModelAccuracy(model, test_dataloader, device)

# Predicting single image

def predict_image(model, image, device, labels=['cloth', 'N95', 'N95 with valve', 'Surgical', "without mask"]):

    model.eval()
    with torch.no_grad():
        image = image.to(device)
        output = model(image.unsqueeze(0))
    pred = output.argmax(dim=1).cpu().numpy()
    print(pred)
    return labels[pred[0]]

image = Image.open("E:\\Masters\\Concordia\\Winter 2022\\COMP 6721\\Project\\Dataset\\train\\Surgical\\SM 200.jpg")
transform = transforms.Compose(
      [transforms.ToTensor(),
        transforms.Resize((32, 32)),
        transforms.Normalize(mean=(6.4307e-02, -6.7064e-05, -2.5857e-03), std=(0.9544, 0.9539, 0.9665))]
  )
image = transform(image)
print(predict_image(model, image, device))